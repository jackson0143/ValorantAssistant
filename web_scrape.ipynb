{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Eunha\\Documents\\Personal work\\ValorantAssistant\\myenv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install -q requests beautifulsoup4 tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://valorant.fandom.com\"\n",
    "AGENTS_PAGE = \"https://valorant.fandom.com/wiki/Agents\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agent_links():\n",
    "    res = requests.get(AGENTS_PAGE)\n",
    "    soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "    agent_links = []\n",
    "    # Find the main agents table\n",
    "    table = soup.find(\"table\", class_=\"wikitable sortable\")\n",
    "    if not table:\n",
    "        print(\"Could not find agents table\")\n",
    "        return []\n",
    "\n",
    "    rows = table.find_all(\"tr\")\n",
    "    for row in rows:\n",
    "        # Get the second cell which has agent link\n",
    "        cells = row.find_all(\"td\")\n",
    "        if len(cells) > 1:\n",
    "            cell = cells[1]\n",
    "            link = cell.find(\"a\")\n",
    "            if link and link.get(\"href\") and \"/wiki/\" in link.get(\"href\"):\n",
    "                agent_links.append(BASE_URL + link.get(\"href\"))\n",
    "    return list(set(agent_links))\n",
    "\n",
    "\n",
    "def parse_agent_page(url):\n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "    \n",
    "    try:\n",
    "        # Get basic info\n",
    "        name = soup.find(\"h1\", id=\"firstHeading\").text.strip()\n",
    "\n",
    "        info_box = soup.find_all('section', class_='pi-item pi-group pi-border-color pi-collapse pi-collapse-open')\n",
    "        bio_box = info_box[0]\n",
    "        game_details_box= info_box[1]\n",
    "        bio_info = {}\n",
    "        if bio_box:\n",
    "            bio_field_mapping = {\n",
    "                'realname': 'real_name',\n",
    "                'aliases': 'aliases',\n",
    "                'pronouns': 'pronouns',\n",
    "                'origin': 'origin',\n",
    "                'race': 'race',\n",
    "                'number': 'agent_number',\n",
    "                \n",
    "            }\n",
    "\n",
    "            # Find all data items in the info box\n",
    "            for data_item in bio_box.find_all('div', class_='pi-item pi-data pi-item-spacing pi-border-color'):\n",
    "           \n",
    "                source = data_item.get('data-source')\n",
    "                if source in bio_field_mapping:\n",
    "                    value_div = data_item.find('div', class_='pi-data-value')\n",
    "                    if value_div:\n",
    "                        bio_info[bio_field_mapping[source]] = ' '.join(value_div.stripped_strings)\n",
    "\n",
    "        #game details box\n",
    "        game_info = {}\n",
    "        if game_details_box:\n",
    "            game_field_mapping = {\n",
    "                'role': 'role',\n",
    "                'role_link': 'role_link',\n",
    "                'basic': 'basic',\n",
    "                'basic_link': 'basic_link',\n",
    "                'signature': 'signature',\n",
    "                'signature_link': 'signature_link',\n",
    "                'ultimate': 'ultimate',    \n",
    "                'ultimate_link': 'ultimate_link',\n",
    "            }\n",
    "    \n",
    "            for data_item in game_details_box.find_all('div', class_='pi-item pi-data pi-item-spacing pi-border-color'):\n",
    "                source = data_item.get('data-source')\n",
    "\n",
    "                if source in game_field_mapping:\n",
    "                    value_div = data_item.find('div', class_='pi-data-value')\n",
    "                    if value_div:\n",
    "                        game_info[game_field_mapping[source]] = ' '.join(value_div.stripped_strings)\n",
    "    \n",
    "                    link = data_item.find(\"a\")\n",
    "                    if link and link.get(\"href\") and \"/wiki/\" in link.get(\"href\"):\n",
    "                        game_info[game_field_mapping[source+'_link']] = BASE_URL + link.get(\"href\")\n",
    "        return {\n",
    "            \"agent\": name,\n",
    "            # \"role\": role,\n",
    "            \"biography\": bio_info,  # Add the biographical information\n",
    "            \"abilities\": game_info,\n",
    "            \"url\": url\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing {url}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:09<00:00,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Done! Scraped 27 agents.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    agent_links = get_agent_links()\n",
    "    \n",
    "    all_agents = []\n",
    "\n",
    "    for link in tqdm(agent_links):\n",
    "        agent_data = parse_agent_page(link)\n",
    "        if agent_data:\n",
    "            all_agents.append(agent_data)\n",
    "\n",
    "    with open(\"data/valorant_agents.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(all_agents, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"‚úÖ Done! Scraped {len(all_agents)} agents.\")\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Eunha\\Documents\\Personal work\\ValorantAssistant\\myenv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip -q install langchain langchain-openai chromadb python-dotenv langchain-chroma\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert JSON to plain text chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"data/valorant_agents.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    agents = json.load(f)\n",
    "\n",
    "from langchain.schema.document import Document\n",
    "\n",
    "# Your agent loop\n",
    "docs = []\n",
    "for agent in agents:\n",
    "    name = agent[\"agent\"]\n",
    "    bio = agent[\"biography\"]\n",
    "    ab = agent[\"abilities\"]\n",
    "\n",
    "    text = f\"\"\"Agent: {name}\n",
    "    Real Name: {bio.get(\"real_name\", \"Unknown\")}\n",
    "    Pronouns: {bio.get(\"pronouns\", \"Unknown\")}\n",
    "    Origin: {bio.get(\"origin\", \"Unknown\")}\n",
    "    Race: {bio.get(\"race\", \"Unknown\")}\n",
    "    Agent Number: {bio.get(\"agent_number\", \"Unknown\")}\n",
    "    Role: {ab.get(\"role\", \"Unknown\")}\n",
    "\n",
    "    Abilities:\n",
    "    - Basic: {ab.get(\"basic\", \"N/A\")}\n",
    "    - Signature: {ab.get(\"signature\", \"N/A\")}\n",
    "    - Ultimate: {ab.get(\"ultimate\", \"N/A\")}\n",
    "    Wiki: {agent.get(\"url\", \"\")}\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Merge all fields into metadata\n",
    "    metadata = {\n",
    "        \"agent\": name,\n",
    "        \"role\": ab.get(\"role\"),\n",
    "        **bio,  # flatten biography into metadata\n",
    "        \"agent_url\": agent.get(\"url\"),\n",
    "        \"basic_link\": ab.get(\"basic_link\"),\n",
    "        \"signature_link\": ab.get(\"signature_link\"),\n",
    "        \"ultimate_link\": ab.get(\"ultimate_link\")\n",
    "    }\n",
    "    docs.append(Document(page_content=text.strip(), metadata=metadata))\n",
    "\n",
    "    \n",
    "import json\n",
    "from langchain.schema.document import Document\n",
    "exportable_docs = []\n",
    "for doc in docs:\n",
    "    exportable_docs.append({\n",
    "        \"content\": doc.page_content,\n",
    "        \"metadata\": doc.metadata\n",
    "    })\n",
    "\n",
    "# Save to file\n",
    "with open(\"data/valorant_chunks.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(exportable_docs, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embed the text chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data embedded and stored in Chroma!\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load OpenAI API key\n",
    "load_dotenv()\n",
    "\n",
    "# Set up embedding model\n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Create or load Chroma vector store\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embedding,\n",
    "    persist_directory=\"data/chroma_store\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Data embedded and stored in Chroma!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BACKUP, DELETE IF NEEDED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting existing Chroma store...\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[WinError 32] The process cannot access the file because it is being used by another process: 'data/chroma_store\\\\20d75822-54f4-40ff-8f96-5977f852dd7e\\\\data_level0.bin'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[125], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/chroma_store\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeleting existing Chroma store...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m     \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrmtree\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/chroma_store\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Existing store deleted\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\shutil.py:739\u001b[0m, in \u001b[0;36mrmtree\u001b[1;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;66;03m# can't continue even if onerror hook returns\u001b[39;00m\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 739\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_rmtree_unsafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monerror\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\shutil.py:612\u001b[0m, in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    610\u001b[0m         onerror(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mislink, fullname, sys\u001b[38;5;241m.\u001b[39mexc_info())\n\u001b[0;32m    611\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 612\u001b[0m     \u001b[43m_rmtree_unsafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monerror\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\shutil.py:617\u001b[0m, in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    615\u001b[0m             os\u001b[38;5;241m.\u001b[39munlink(fullname)\n\u001b[0;32m    616\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m--> 617\u001b[0m             \u001b[43monerror\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munlink\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    619\u001b[0m     os\u001b[38;5;241m.\u001b[39mrmdir(path)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\shutil.py:615\u001b[0m, in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 615\u001b[0m         \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munlink\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    616\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m    617\u001b[0m         onerror(os\u001b[38;5;241m.\u001b[39munlink, fullname, sys\u001b[38;5;241m.\u001b[39mexc_info())\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 32] The process cannot access the file because it is being used by another process: 'data/chroma_store\\\\20d75822-54f4-40ff-8f96-5977f852dd7e\\\\data_level0.bin'"
     ]
    }
   ],
   "source": [
    "# Close existing Chroma connection\n",
    "if 'vectorstore' in globals():\n",
    "    del vectorstore\n",
    "    print(\"Closed existing Chroma connection\")\n",
    "# Delete existing Chroma store\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Check if the directory exists before trying to delete it\n",
    "if os.path.exists(\"data/chroma_store\"):\n",
    "    print(\"Deleting existing Chroma store...\")\n",
    "    shutil.rmtree(\"data/chroma_store\")\n",
    "    print(\"‚úÖ Existing store deleted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of agents by role:\n",
      "Controller: 6 agents\n",
      "Initiator: 7 agents\n",
      "Sentinel: 6 agents\n",
      "Duelist: 8 agents\n",
      "\n",
      "Total unique agents: 27\n",
      "\n",
      "Testing queries:\n",
      "\n",
      "Query: which agent is from Australia?\n",
      "Score: 1.1419 - Skye (Initiator)\n",
      "Score: 1.2342 - Phoenix (Duelist)\n",
      "Score: 1.2455 - Chamber (Sentinel)\n",
      "\n",
      "Query: Which agent is from Korea?\n",
      "Score: 1.1517 - KAY/O (Initiator)\n",
      "Score: 1.1697 - Iso (Duelist)\n",
      "Score: 1.1821 - Yoru (Duelist)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Get all documents from the store\n",
    "all_docs = vectorstore.get()\n",
    "if all_docs and 'metadatas' in all_docs:\n",
    "    # Count roles\n",
    "    roles = [doc['role'] for doc in all_docs['metadatas']]\n",
    "    role_counts = Counter(roles)\n",
    "    print(\"Distribution of agents by role:\")\n",
    "    for role, count in role_counts.items():\n",
    "        print(f\"{role}: {count} agents\")\n",
    "    \n",
    "    # Count unique agents\n",
    "    agents = [doc['agent'] for doc in all_docs['metadatas']]\n",
    "    unique_agents = set(agents)\n",
    "    print(f\"\\nTotal unique agents: {len(unique_agents)}\")\n",
    "    \n",
    "    # Test a few queries to verify embeddings\n",
    "    test_queries = [\n",
    "        \"which agent is from Australia?\",\n",
    "        \"Which agent is from Korea?\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nTesting queries:\")\n",
    "    for query in test_queries:\n",
    "        print(f\"\\nQuery: {query}\")\n",
    "        results = vectorstore.similarity_search_with_score(query, k=3)\n",
    "        for doc, score in results:\n",
    "            print(f\"Score: {score:.4f} - {doc.metadata['agent']} ({doc.metadata['role']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Agent: Iso\n",
      "Agent: Iso\n",
      "    Real Name: Li Zhao Yu\n",
      "    Pronouns: He/Him\n",
      "    Origin: Chongqing, China\n",
      "    Race: Radiant\n",
      "    Agent Number: 24\n",
      "    Role: Duelist\n",
      "\n",
      "    Abilities:\n",
      "    - Basic: Contingency Undercut\n",
      "    - Signature: Double Tap\n",
      "    - Ultimate: Kill Contract\n",
      "    Wiki: https://valorant.fandom.com/wiki/Iso\n",
      "üîó Link: https://valorant.fandom.com/wiki/Contingency\n"
     ]
    }
   ],
   "source": [
    "# Load existing Chroma\n",
    "vectorstore = Chroma(\n",
    "    persist_directory=\"data/chroma_store\",\n",
    "    embedding_function=embedding\n",
    ")\n",
    "\n",
    "# Query it\n",
    "# Example queries you could try:\n",
    "\n",
    "query = \"Which agent is from China?\"\n",
    "results = vectorstore.similarity_search(query, k=1)\n",
    "\n",
    "# Print results\n",
    "for doc in results:\n",
    "    print(\"Matched Agent:\", doc.metadata[\"agent\"])\n",
    "    print(doc.page_content)\n",
    "\n",
    "    #This is any metadata that is not part of the content that i want to include for the agent\n",
    "    print(\"üîó Link:\", doc.metadata[\"basic_link\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query with metadata filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iso - Chongqing, China\n",
      "Waylay - Thailand\n"
     ]
    }
   ],
   "source": [
    "filtered_docs = vectorstore.similarity_search(\n",
    "    \"Which agent uses knives?\",\n",
    "    k=2,\n",
    "    filter={\"role\": \"Duelist\"}\n",
    ")\n",
    "\n",
    "for doc in filtered_docs:\n",
    "    print(doc.metadata[\"agent\"], \"-\", doc.metadata[\"origin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí¨ Answer:\n",
      " Jett's basic ability is **Cloudburst**. This ability allows her to throw a projectile that expands into a brief vision-blocking cloud on impact with the ground. It is particularly useful for obscuring visibility, aiding in her mobility, and creating opportunities to engage or disengage in fights.\n",
      "\n",
      "Additionally, Jett has another basic ability called **Updraft** which allows her to propel herself upward, giving her access to high ground or allowing her to escape.\n",
      "\n",
      "For more detailed information about Jett and her abilities, you can visit her wiki page here: [Jett Wiki](https://valorant.fandom.com/wiki/Jett).\n",
      "üìÑ Source: Jett\n",
      "üìÑ Source: Killjoy\n",
      "üìÑ Source: Tejo\n",
      "üìÑ Source: Deadlock\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    ")\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    # search_kwargs={\"k\": 3}  # Increased to get more context\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "custom_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a Valorant assistant that provides detailed information about agents and their abilities.\n",
    "\n",
    "When answering questions:\n",
    "1. Use the context to provide a comprehensive answer\n",
    "2. If the question is about abilities, include the relevant URLs from the metadata. If the metadata doesn't contain the requested URL, say \"URL not found in metadata\"\n",
    "3. Format your response in a clear, organized way\n",
    "4. If the question is not about Valorant, respond with \"Sorry, please ask a question related to Valorant.\"\n",
    "\n",
    "For example, if asked about an agent's abilities, include both the description from the context AND the relevant URLs from the metadata.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer: Provide a detailed answer and include relevant URLs from the metadata when discussing abilities.\n",
    "\"\"\")\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",\n",
    "    chain_type_kwargs={\"prompt\": custom_prompt},\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "query = \"What is jett's basic ability?\"\n",
    "result = qa_chain.invoke({\"query\": query})\n",
    "\n",
    "print(\"üí¨ Answer:\\n\", result[\"result\"])\n",
    "# print(\"üîç Metadata:\", result[\"source_documents\"][0].metadata[\"basic_link\"])  # This will show us the actual metadata value\n",
    "# Optional: view source docs used\n",
    "for doc in result[\"source_documents\"]:\n",
    "    print(\"üìÑ Source:\", doc.metadata[\"agent\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
